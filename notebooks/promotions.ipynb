{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\n",
      "  Using cached langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from langchain_openai) (0.2.6)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.26.0 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from langchain_openai) (1.34.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (0.1.77)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (2.7.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (8.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain_openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain_openai) (3.10.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain_openai) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.1)\n",
      "Downloading langchain_openai-0.1.8-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: langchain_openai\n",
      "Successfully installed langchain_openai-0.1.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_core.runnables import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt for fav_and_least_fav_product_type_promotional_text_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an Expert in writing promotional text and offer texts personalized for a given user. \n",
    "you are given some information about the customer and you have to write a promotional text for a product of the favourite product type and a product of the least favourite product type to boost their sales.\n",
    "Refer to the offer_context for most common product of each type. Also you can create similar product for a given type. ALWAYS PROVIDE A PRODUCT NAME IN THE PROMOTIONAL TEXT. \n",
    "Here are the information all time favourite product categories of the customer:\n",
    "{customer_info}: \n",
    "input format for customer_info= \"{{Favourite product type: {{product_type}}, Least Favourite product type: {{product_type}},}}\"\n",
    "}}\"\n",
    "\n",
    "Influence by below sample offers for different product categories to create example promotional text based on the product types, be creative and use more words:\n",
    "{offer_context}\n",
    "\n",
    "based on above information provide the promotional text for the favourite product type and least favourite product type.\n",
    "\n",
    "Final JSON output format= \n",
    "\"{{Favourite product type: GENERATED PROMOTIONAL TEXT FOR FAVOURITE PRODUCT TYPE,\n",
    "Least Favourite product type: GENERATED PROMOTIONAL TEXT FOR LEAST FAVOURITE PRODUCT TYPE,}}\"\n",
    "\n",
    "No need opening or ending paragraph, provide the JSON file ONLY.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "fav_and_least_fav_product_type_promotional_text_template = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### define retriever\n",
    "pdf_loader = PyPDFDirectoryLoader('../promotional texts')\n",
    "\n",
    "docs = pdf_loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=100, chunk_overlap=20)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "len(split_docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embeddings = HuggingFaceBgeEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# vector_store = FAISS.from_documents(\n",
    "#     documents=split_docs,\n",
    "#     embedding=embeddings,\n",
    "# )\n",
    "\n",
    "# save the vector store to disk\n",
    "# vector_store.save_local(\"vector_stores/promotional_texts\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the vector store from disk\n",
    "vector_store = FAISS.load_local(folder_path=\"/Users/vihidun/Desktop/Finals_Datastorm_5/Finals-datastorm/database/vectordb\", embeddings=embeddings,allow_dangerous_deserialization=True)\n",
    "\n",
    "retriever_promotional_texts = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get customer_info\n",
    "import pandas as pd\n",
    "\n",
    "def get_customer_info_fav_and_leastfav_info(customer_info_csv_path: str, customer_code: str):\n",
    "    df = pd.read_csv(customer_info_csv_path)\n",
    "\n",
    "    customer_df = df[df['customer_code'] == customer_code]\n",
    "\n",
    "    customer_df['total_sales_quantity_breakdown'] = customer_df['total_sales_quantity_breakdown'].str.rstrip('%').astype(float)\n",
    "\n",
    "    favorite_product_type = customer_df.loc[customer_df['total_sales_quantity_breakdown'].idxmax()]['level_1']\n",
    "\n",
    "    least_favorite_product_type = customer_df.loc[customer_df['total_sales_quantity_breakdown'].idxmin()]['level_1']\n",
    "\n",
    "    result = {\n",
    "        'Favourite product type': favorite_product_type,\n",
    "        'Least Favourite product type': least_favorite_product_type\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Favourite product type': 'fresh-fruits', 'Least Favourite product type': 'household-baby_needs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/z8dhpprj11b1w1rsyp3fh4zr0000gn/T/ipykernel_94533/1377543895.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  customer_df['total_sales_quantity_breakdown'] = customer_df['total_sales_quantity_breakdown'].str.rstrip('%').astype(float)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "result = get_customer_info_fav_and_leastfav_info(\"../synthesized_data/total_sales_quantity_breakdown_by_department_item_category_df.csv\", 'customer_code_1')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"Favourite product type\": \"Celebrate Your Health! Get 20% off on our fresh fruits basket and enjoy the natural goodness of our products.\",\n",
      "\"Least Favourite product type\": \"Give Our Baby Essentials Another Try! Enjoy a special 25% discount on your next purchase and discover the convenience and quality of our household and baby needs.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(api_key='sk-proj-tiF6IMRa0jWHMbLr759UT3BlbkFJGxs97SwfOLb4VvvtxvVT', temperature=0.90, model_kwargs={\"top_p\": 0.9})\n",
    "\n",
    "rag_chain = (\n",
    "    {'customer_info': RunnablePassthrough(), 'offer_context': retriever_promotional_texts}\n",
    "    | fav_and_least_fav_product_type_promotional_text_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "RESPONSE = rag_chain.invoke(str(result))\n",
    "\n",
    "print(RESPONSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_customer_info_highV_and_lowV_info(highV_df: str, lowV_df: str, customer_code: str, month:int):\n",
    "    highV_df = pd.read_csv(highV_df)\n",
    "    lowV_df = pd.read_csv(lowV_df)\n",
    "\n",
    "    highV_filtered = highV_df[(highV_df['customer_code'] == customer_code) & (highV_df['month'] == month)]\n",
    "    lowV_filtered = lowV_df[(lowV_df['customer_code'] == customer_code) & (lowV_df['month'] == month)]\n",
    "    \n",
    "    # Get the highest volume product type\n",
    "    highest_volume_product = highV_filtered.loc[highV_filtered['volume'].idxmax()]['department_item_category']\n",
    "    \n",
    "    # Get the lowest volume product type\n",
    "    lowest_volume_product = lowV_filtered.loc[lowV_filtered['volume'].idxmin()]['department_item_category']\n",
    "    \n",
    "    # Create the JSON output\n",
    "    customer_info = {\n",
    "        \"Highest volume product type\": highest_volume_product,\n",
    "        \"Lowest volume product type\": lowest_volume_product\n",
    "    }\n",
    "    \n",
    "    return customer_info\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Highest volume product type': 'animal products-frozen_meat', 'Lowest volume product type': 'Hygiene-beauty_and_personal_care'}\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "res = get_customer_info_highV_and_lowV_info(\"../synthesized_data/top3_department_item_category.csv\", \"../synthesized_data/bottom3_department_item_category.csv\", 'customer_code_1', 1)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an Expert in writing promotional text and offer texts personalized for a given user. \n",
    "You are given some information about the customer's transaction history and you have to write a promotional text for a product of the highest volume sales product type and a product of the lowest volume sales product type to boost their sales.\n",
    "Refer to the offer_context for the most common product of each type. You can also create similar products for a given type. ALWAYS PROVIDE A PRODUCT NAME IN THE PROMOTIONAL TEXT. \n",
    "Here is the information about the customer's transaction history: EXTREMELY IMPORTANT TO GENERATE PROMOTIONAL TEXT EMPHASIZING THE BULK BEHAVIOR OF THE CUSTOMER\n",
    "{customer_info}: \n",
    "input format for customer_info= \"{{Highest volume product type: {{product_type}}, Lowest volume product type: {{product_type}},}}\"\n",
    "}}\"\n",
    "\n",
    "Influence by the below sample offers for different product categories to create example promotional text based on the product types, be creative and use more words:\n",
    "{offer_context}\n",
    "\n",
    "Based on the above information, provide the promotional text for the highest volume product type and the lowest volume product type.\n",
    "\n",
    "Final JSON output format= \n",
    "\"{{Highest volume product type: GENERATED PROMOTIONAL TEXT FOR HIGHEST VOLUME PRODUCT TYPE,\n",
    "Lowest volume product type: GENERATED PROMOTIONAL TEXT FOR LOWEST VOLUME PRODUCT TYPE,}}\"\n",
    "\n",
    "No need for an opening or ending paragraph, provide the JSON file ONLY.\n",
    "\"\"\"\n",
    "\n",
    "highest_and_lowest_volume_product_type_promotional_text_template = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"Highest volume product type\": \"Enjoy the freshness of nature with our top-selling 'Frozen Meat Variety Pack'. Stock up now and save more with our exclusive bulk discount!\",\n",
      "\"Lowest volume product type\": \"Give our 'Beauty and Personal Care Essentials Set' another try with a special 25% discount on your next purchase. Rediscover the benefits today!\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "rag_chain_vol = (\n",
    "    {'customer_info': RunnablePassthrough(), 'offer_context': retriever_promotional_texts}\n",
    "    | highest_and_lowest_volume_product_type_promotional_text_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "RESPONSE = rag_chain_vol.invoke(str(res))\n",
    "\n",
    "print(RESPONSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def get_current_month():\n",
    "    current_month = datetime.datetime.now().month\n",
    "    return current_month\n",
    "\n",
    "# Example usage\n",
    "current_month = get_current_month()\n",
    "type(current_month)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "featuren",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
